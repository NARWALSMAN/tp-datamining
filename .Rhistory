indices <- createDataPartition(data$Species, p = 0.7, list = FALSE)
formation <- data[indices, ]
test <- data[-indices, ]
# Appliquer LDA
modele_lda <- lda(Species ~ ., data = formation)
predictions <- predict(modele_lda, test)$class
# Calculer le taux d'erreur et la précision
matrice_confusion <- table(predictions, test$Species)
taux_erreur <- 1 - sum(diag(matrice_confusion)) / sum(matrice_confusion)
precision <- diag(matrice_confusion) / rowSums(matrice_confusion)
# Stocker les résultats
resultats[[i]] <- list(taux_erreur = taux_erreur, precision = precision)
}
return(resultats)
}
#QUESTION 6
# Exécuter l'étude de rééchantillonnage
resultats_reechantillonnage_lda <- effectuer_reechantillonnage_lda(data_iris, n_splits = 500)
resultats_reechantillonnage_lda
# Extraction des taux d'erreurs à partir des résultats
taux_erreurs <- sapply(resultats_reechantillonnage_lda, function(x) x$taux_erreur)
# Extraction des précisions pour chaque classe (setosa, virginica, versicolor)
# en supposant que l'ordre des classes est le même pour toutes les précisions
precisions <- do.call(rbind, lapply(resultats_reechantillonnage_lda, function(x) x$precision))
precisions_setosa <- precisions[, "setosa"]
precisions_virginica <- precisions[, "virginica"]
precisions_versicolor <- precisions[, "versicolor"]
# Configuration de l'espace de tracé pour afficher trois graphiques côte à côte
par(mfrow = c(1, 4))
# Tracé du boxplot pour les taux d'erreurs
boxplot(taux_erreurs, main = "Taux d'Erreurs", ylab = "Taux d'Erreur")
# Tracé des boxplots pour les précisions de chaque classe
boxplot(precisions_setosa, main = "Précision Setosa", ylab = "Précision")
boxplot(precisions_virginica, main = "Précision Virginica", ylab = "Précision")
boxplot(precisions_versicolor, main = "Précision Versicolor", ylab = "Précision")
# Restaurer la configuration par défaut de l'espace de tracé
par(mfrow = c(1, 1))
#QUESTION 7
# selection_results <- resultats_reechantillonnage_lda
# # Créer une matrice pour stocker les résultats
# var_names <- unique(unlist(selection_results))  # Toutes les variables uniques
# selection_matrix <- matrix(0, nrow = length(var_names), ncol = length(var_names))
# rownames(selection_matrix) <- var_names
#
# # Remplir la matrice avec les occurrences
# for (selection in selection_results) {
#   for (i in seq_along(selection)) {
#     variable <- selection[i]
#     selection_matrix[variable, i] <- selection_matrix[variable, i] + 1
#   }
# }
#
# # Créer le tableau de contingence
# contingency_table <- as.table(selection_matrix)
#
# # Afficher le tableau3
# print(contingency_table)
# #########################################################################
# Créer une matrice pour stocker les résultats
var_names <- unique(unlist(selection_results))  # Toutes les variables uniques
selection_matrix <- matrix(0, nrow = length(var_names), ncol = length(selection_results))
rownames(selection_matrix) <- var_names
# Remplir la matrice avec les occurrences
for (i in seq_along(selection_results)) {
selection <- selection_results[[i]]
for (variable in selection) {
# S'assurer que 'variable' est un seul élément
if (length(variable) == 1 && variable %in% rownames(selection_matrix)) {
selection_matrix[variable, i] <- selection_matrix[variable, i] + 1
}
}
}
# Créer le tableau de contingence
contingency_table <- as.table(selection_matrix)
# Afficher le tableau
print(contingency_table)
#ARBRE QUESTION 1
# Load necessary libraries
library(rpart)
library(rpart.plot)
# Prepare the data
data(iris)
X <- iris[, 1:4]   # Selecting the features
y <- iris[, 5]     # Selecting the target variable
# Splitting the data into training and test sets
# First 25 observations of each species for training
ind.train <- c(1:25, 51:75, 101:125)
X.train <- X[ind.train, ]
y.train <- y[ind.train]
# Create a data frame for training
dat.train <- data.frame(cbind(X.train, y.train = y.train))
# Building the decision tree
arbre <- rpart(y.train ~ ., data = dat.train)
# Print the tree structure
print(arbre)
# Visualizing the tree
rpart.plot(arbre)
# Prepare the data
data(iris)
X <- iris[, 1:4]   # Selecting the features
y <- iris[, 5]     # Selecting the target variable
# Splitting the data into training and test sets
# First 25 observations of each species for training
ind.train <- c(1:25, 51:75, 101:125)
X.train <- X[ind.train, ]
y.train <- y[ind.train]
# Create a data frame for training
dat.train <- data.frame(cbind(X.train, y.train = y.train))
# Building the decision tree
arbre <- rpart(y.train ~ ., data = dat.train)
# Print the tree structure
print(arbre)
# Visualizing the tree
rpart.plot(arbre)
# Paramètres de pré-élagage
control_params <- rpart.control(maxdepth = 30, minsplit = 20, minbucket = 7, cp = 0.01)
# Construction de l'arbre avec pré-élagage
arbre_pre_elagage <- rpart(y.train ~ ., data=dat.train, control=control_params)
# Visualiser l'arbre pré-élagué
rpart.plot(arbre_pre_elagage)
# Calcul du cp optimal
seuil <- min(arbre_pre_elagage$cptable[, "xerror"] + arbre_pre_elagage$cptable[, "xstd"])
cpadm <- arbre_pre_elagage$cptable[arbre_pre_elagage$cptable[, "xerror"] <= seuil, ]
cpopti <- cpadm[1, "CP"]
# Paramètres de pré-élagage
control_params <- rpart.control(maxdepth = 30, minsplit = 20, minbucket = 7, cp = 0.01)
# Construction de l'arbre avec pré-élagage
arbre_pre_elagage <- rpart(y.train ~ ., data=dat.train, control=control_params)
# Visualiser l'arbre pré-élagué
rpart.plot(arbre_pre_elagage)
# Paramètres de pré-élagage
control_params <- rpart.control(maxdepth = 30, minsplit = 20, minbucket = 7, cp = 0.01)
# Construction de l'arbre avec pré-élagage
arbre_pre_elagage <- rpart(y.train ~ ., data=dat.train, control=control_params)
# Visualiser l'arbre pré-élagué
rpart.plot(arbre_pre_elagage)
# Calcul du cp optimal
seuil <- min(arbre_pre_elagage$cptable[, "xerror"] + arbre_pre_elagage$cptable[, "xstd"])
cpadm <- arbre_pre_elagage$cptable[arbre_pre_elagage$cptable[, "xerror"] <= seuil, ]
cpopti <- cpadm[1, "CP"]
# Calcul du cp optimal
cptable <- arbre_pre_elagage$cptable
seuil <- min(cptable[,"xerror"] + cptable[,"xstd"])
cpadm <- cptable[cptable[,"xerror"] <= seuil, ]
# S'assurer que cpadm est un dataframe ou une matrice
if (is.null(cpadm) || nrow(cpadm) == 0) {
stop("Aucune entrée dans cpadm ne répond au critère du seuil.")
}
# Calcul du cp optimal
cptable <- arbre_pre_elagage$cptable
seuil <- min(cptable[,"xerror"] + cptable[,"xstd"])
cpadm <- cptable[cptable[,"xerror"] <= seuil, ]
# Vérifier si cpadm est vide ou non, et s'assurer de ne pas avoir de NA
if (is.null(cpadm) || nrow(cpadm) == 0 || is.na(nrow(cpadm))) {
stop("Aucune entrée dans cpadm ne répond au critère du seuil.")
}
# Calcul du cp optimal
cptable <- arbre_pre_elagage$cptable
seuil <- min(cptable[,"xerror"] + cptable[,"xstd"])
cpadm <- cptable[cptable[,"xerror"] <= seuil, ]
# Vérifier si cpadm est vide ou non, et s'assurer de ne pas avoir de NA
if (is.null(cpadm) || nrow(cpadm) == 0 || is.na(nrow(cpadm))) {
stop("Aucune entrée dans cpadm ne répond au critère du seuil.")
}
# Calcul du seuil
cptable <- arbre_pre_elagage$cptable
seuil <- min(cptable[,"xerror"] + cptable[,"xstd"], na.rm = TRUE)
# Filtrer cpadm
cpadm <- cptable[cptable[,"xerror"] <= seuil, ]
# Vérifier si cpadm est vide ou contient des NA
if (is.null(cpadm) || nrow(cpadm) == 0 || any(is.na(cpadm[,"xerror"]))) {
stop("Aucune entrée valide dans cpadm.")
}
# Calcul du seuil
cptable <- arbre_pre_elagage$cptable
seuil <- min(cptable[,"xerror"] + cptable[,"xstd"], na.rm = TRUE)
# Filtrer cpadm
cpadm <- cptable[cptable[,"xerror"] <= seuil, ]
# Vérifier la structure de cpadm
if (is.null(cpadm) || nrow(cpadm) == 0 || !is.data.frame(cpadm)) {
stop("cpadm n'est pas un dataframe ou est vide.")
}
# Calculer le cp directement
cptable <- arbre_pre_elagage$cptable
cpopti_line <- which.min(cptable[, "xerror"] + cptable[, "xstd"])
cpopti <- cptable[cpopti_line, "CP"]
# Vérifier que cpopti est valide
if (is.na(cpopti)) {
stop("Impossible de déterminer un CP optimal.")
}
# Élagage de l'arbre avec le CP optimal
arbre_post_elagage <- prune(arbre_pre_elagage, cp = cpopti)
# Visualiser l'arbre post-élagué
rpart.plot(arbre_post_elagage)
# Calculer le cp directement
cptable <- arbre_pre_elagage$cptable
cpopti_line <- which.min(cptable[, "xerror"] + cptable[, "xstd"])
cpopti <- cptable[cpopti_line, "CP"]
# Vérifier que cpopti est valide
if (is.na(cpopti)) {
stop("Impossible de déterminer un CP optimal.")
}
# Élagage de l'arbre avec le CP optimal
arbre_post_elagage <- prune(arbre_pre_elagage, cp = cpopti)
# Visualiser l'arbre post-élagué
rpart.plot(arbre_post_elagage)
# Calculer le cp directement
cptable <- arbre_pre_elagage$cptable
cpopti_line <- which.min(cptable[, "xerror"] + cptable[, "xstd"])
cpopti <- cptable[cpopti_line, "CP"]
# Vérifier que cpopti est valide
if (is.na(cpopti)) {
stop("Impossible de déterminer un CP optimal.")
}
# Élagage de l'arbre avec le CP optimal
arbre_post_elagage <- prune(arbre_pre_elagage, cp = cpopti)
# Visualiser l'arbre post-élagué
rpart.plot(arbre_post_elagage)
# Calcul du cp optimal
seuil <- min(arbre_pre_elagage$cptable[, "xerror"] + arbre_pre_elagage$cptable[, "xstd"])
cpadm <- arbre_pre_elagage$cptable[arbre_pre_elagage$cptable[, "xerror"] <= seuil, ]
cpopti <- cpadm[1, "CP"]
# Calcul du cp optimal
seuil <- min(arbre_pre_elagage$cptable[, "xerror"] + arbre_pre_elagage$cptable[, "xstd"])
cpadm <- arbre_pre_elagage$cptable[arbre_pre_elagage$cptable[, "xerror"] <= seuil, ]
cpopti <- cpadm[1, "CP"]
# Calculer l'indice de la ligne avec le xerror minimum augmenté de xstd
cpopti_line <- which.min(arbre_pre_elagage$cptable[, "xerror"] + arbre_pre_elagage$cptable[, "xstd"])
cpopti <- arbre_pre_elagage$cptable[cpopti_line, "CP"]
# Vérifier que cpopti est valide
if (is.na(cpopti)) {
stop("Impossible de déterminer un CP optimal.")
}
# Élagage de l'arbre avec le CP optimal
arbre_post_elagage <- prune(arbre_pre_elagage, cp = cpopti)
# Visualiser l'arbre post-élagué
rpart.plot(arbre_post_elagage)
# Calculer l'indice de la ligne avec le xerror minimum augmenté de xstd
cpopti_line <- which.min(arbre_pre_elagage$cptable[, "xerror"] + arbre_pre_elagage$cptable[, "xstd"])
cpopti <- arbre_pre_elagage$cptable[cpopti_line, "CP"]
# Vérifier que cpopti est valide
if (is.na(cpopti)) {
stop("Impossible de déterminer un CP optimal.")
}
# Élagage de l'arbre avec le CP optimal
arbre_post_elagage <- prune(arbre_pre_elagage, cp = cpopti)
# Visualiser l'arbre post-élagué
rpart.plot(arbre_post_elagage)
# Préparation de l'échantillon de test
ind.test <- setdiff(1:nrow(iris), ind.train)
X.test <- iris[ind.test, 1:4]
y.test <- iris[ind.test, 5]
# Prédiction avec l'arbre par défaut
predictions_default <- predict(arbre, X.test, type = "class")
# Prédiction avec l'arbre pré-élagué
predictions_pre_elagage <- predict(arbre_pre_elagage, X.test, type = "class")
# Prédiction avec l'arbre post-élagué
predictions_post_elagage <- predict(arbre_post_elagage, X.test, type = "class")
# Évaluer les performances
table(y.test, predictions_default)
table(y.test, predictions_pre_elagage)
table(y.test, predictions_post_elagage)
# Scores d'importance pour chaque arbre
importance_default <- arbre$variable.importance
importance_pre_elagage <- arbre_pre_elagage$variable.importance
importance_post_elagage <- arbre_post_elagage$variable.importance
# Afficher les scores
print(importance_default)
print(importance_pre_elagage)
print(importance_post_elagage)
#étude de réechantillonage
etude_reechantillonnage <- function(N) {
resultats <- list()
for (i in 1:N) {
set.seed(i)
ind.train <- sample(1:nrow(iris), size = floor(0.7 * nrow(iris)))
y.train <- iris[ind.train, 5]
X.train <- iris[ind.train, 1:4]
dat.train <- data.frame(X.train, y.train)
arbre <- rpart(y.train ~ ., data=dat.train, control=control_params)
ind.test <- setdiff(1:nrow(iris), ind.train)
X.test <- iris[ind.test, 1:4]
y.test <- iris[ind.test, 5]
predictions <- predict(arbre, X.test, type = "class")
matrice_confusion <- table(y.test, predictions)
taux_erreur <- 1 - sum(diag(matrice_confusion)) / sum(matrice_confusion)
precision <- diag(matrice_confusion) / rowSums(matrice_confusion)
resultats[[i]] <- list(taux_erreur = taux_erreur, precision = precision, cp = arbre$cp)
}
return(resultats)
}
# Exécuter l'étude de rééchantillonnage
N <- 500
resultats_reechantillonnage <- etude_reechantillonnage(N)
# Analyser les résultats (à compléter selon votre analyse)
# INITIALISATION
library(class)
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
# Charger les données Pokémon
pokemon_data <- read.csv("Pokemon.csv")
# Assurez-vous que les données sont correctement formatées et prétraitées
# Exemple: Gérer les valeurs manquantes, encoder les variables catégorielles, etc.
# QUESTION 1
# Description du fonctionnement de la méthode KNN adaptée au jeu de données Pokémon
# QUESTION 2 - Préparer les données pour le KNN
set.seed(123) # Pour la reproductibilité
# Choix de variables pour l'analyse. Par exemple, utilisons 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed'
# Utilisation de 'Type 1' pour la classification
indices <- createDataPartition(pokemon_data$Type.1, p = 0.7, list = TRUE)
train_set <- pokemon_data[indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp. Atk", "Sp. Def", "Speed", "Type.1")]
library(klaR)
library(caret)
# Charger les données Pokémon
pokemon_data <- read.csv("Pokemon.csv")
# Assurez-vous que les données sont correctement formatées et prétraitées
# Exemple: Gérer les valeurs manquantes, encoder les variables catégorielles, etc.
# QUESTION 1
# Description du fonctionnement de la méthode KNN adaptée au jeu de données Pokémon
# QUESTION 2 - Préparer les données pour le KNN
set.seed(123) # Pour la reproductibilité
# Choix de variables pour l'analyse. Par exemple, utilisons 'Total', 'HP', 'Attack', 'Defense', 'Sp..Atk', 'Sp..Def', 'Speed'
# Utilisation de 'Type 1' pour la classification
indices <- createDataPartition(pokemon_data$Type.1, p = 0.7, list = TRUE)
train_set <- pokemon_data[indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp. Atk", "Sp. Def", "Speed", "Type.1")]
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
# Charger les données Pokémon
pokemon_data <- read.csv("Pokemon.csv")
# Assurez-vous que les données sont correctement formatées et prétraitées
# Exemple: Gérer les valeurs manquantes, encoder les variables catégorielles, etc.
# QUESTION 1
# Description du fonctionnement de la méthode KNN adaptée au jeu de données Pokémon
# QUESTION 2 - Préparer les données pour le KNN
set.seed(123) # Pour la reproductibilité
# Choix de variables pour l'analyse. Par exemple, utilisons 'Total', 'HP', 'Attack', 'Defense', 'Sp..Atk', 'Sp..Def', 'Speed'
# Utilisation de 'Type 1' pour la classification
indices <- createDataPartition(pokemon_data$Type.1, p = 0.7, list = TRUE)
train_set <- pokemon_data[indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed", "Type.1")]
test_set <- pokemon_data[-indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed", "Type.1")]
# QUESTION 3 - Fonction pour le test KNN
fait_un_test <- function(donnertrain, donnertest, classetrain, classetest, k) {
# Adaptation de la fonction pour les données Pokémon
test_resultat <- knn(train = donnertrain[, -ncol(donnertrain)],
test = donnertest[, -ncol(donnertest)],
cl = classetrain,
k = k, use.all = FALSE)
tableau_confusion <- table(classetest, test_resultat)
precision <- sum(diag(tableau_confusion)) / sum(tableau_confusion)
return(precision)
}
# QUESTION 4 - Tester la fonction sur les données Pokémon
# Exemple: trouver le k optimal
liste_k_voisin <- c(3, 5, 7)
k_optimale <- trouve_k_opt(train_set, liste_k_voisin)
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
source("tp.R")
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
source("tp.R")
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
source("tp.R")
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
source("tp.R")
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
source("tp.R")
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
source("tp.R")
# Charger les données Pokémon
pokemon_data <- read.csv("Pokemon.csv")
# QUESTION 2 - Préparer les données pour le KNN
set.seed(123) # Pour la reproductibilité
# Utilisation de 'Type 1' pour la classification
indices <- createDataPartition(pokemon_data$Type.1, p = 0.7, list = TRUE)
train_set <- pokemon_data[indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed", "Type.1")]
test_set <- pokemon_data[-indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed", "Type.1")]
# QUESTION 3 - Fonction pour le test KNN
fait_un_test <- function(donnertrain, donnertest, classetrain, classetest, k) {
# Adaptation de la fonction pour les données Pokémon
test_resultat <- knn(train = donnertrain[, -ncol(donnertrain)],
test = donnertest[, -ncol(donnertest)],
cl = classetrain,
k = k, use.all = FALSE)
tableau_confusion <- table(classetest, test_resultat)
precision <- sum(diag(tableau_confusion)) / sum(tableau_confusion)
return(precision)
}
# QUESTION 4 - Tester la fonction sur les données Pokémon
# Exemple: trouver le k optimal
liste_k_voisin <- c(3, 5, 7)
k_optimale <- trouve_k_opt(train_set, liste_k_voisin)
##################################
# TP Data Mining - Pratique sous R avec Pokémon #
##################################
# INITIALISATION
library(class)
library(MASS)
library(klaR)
library(caret)
source("tp.R")
# Charger les données Pokémon
pokemon_data <- read.csv("Pokemon.csv")
# QUESTION 2 - Préparer les données pour le KNN
set.seed(123) # Pour la reproductibilité
# Utilisation de 'Type 1' pour la classification
indices <- createDataPartition(pokemon_data$Type.1, p = 0.7, list = TRUE)
train_set <- pokemon_data[indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed", "Type.1")]
test_set <- pokemon_data[-indices[[1]], c("Total", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed", "Type.1")]
# QUESTION 3 - Fonction pour le test KNN
fait_un_test <- function(donnertrain, donnertest, classetrain, classetest, k) {
# Adaptation de la fonction pour les données Pokémon
test_resultat <- knn(train = donnertrain[, -ncol(donnertrain)],
test = donnertest[, -ncol(donnertest)],
cl = classetrain,
k = k, use.all = FALSE)
tableau_confusion <- table(classetest, test_resultat)
precision <- sum(diag(tableau_confusion)) / sum(tableau_confusion)
return(precision)
}
# QUESTION 4 - Tester la fonction sur les données Pokémon
# Exemple: trouver le k optimal
liste_k_voisin <- c(3, 5, 7)
k_optimale <- trouve_k_opt(train_set, liste_k_voisin)
# QUESTION 5
etude_reechantillonnage <- function(data, variable_predire, variables_independantes, ks, N) {
taille <- nrow(data)
resultats <- vector("list", N)
for (i in 1:N) {
# Création d'un échantillon aléatoire pour l'apprentissage et le test
indices <- sample(1:taille, size = floor(0.7 * taille))
train_set <- data[indices, ]
test_set <- data[-indices, ]
y_train <- train_set[[variable_predire]]
y_test <- test_set[[variable_predire]]
X_train <- train_set[variables_independantes]
X_test <- test_set[variables_independantes]
# Boucle sur les différentes valeurs de k
erreurs <- numeric(length(ks))
for (j in seq_along(ks)) {
k <- ks[j]
predictions <- knn(train = X_train, test = X_test, cl = y_train, k = k)
erreurs[j] <- mean(predictions != y_test)
}
resultats[[i]] <- erreurs
}
return(resultats)
}
#QUESTION 6
# Paramètres pour l'étude de rééchantillonnage
ks <- c(3, 5, 7, 9, 11, 13)  # différentes valeurs de k à tester
N <- 100  # nombre de répétitions pour l'étude
# Exécution de l'étude de rééchantillonnage
resultats_reechantillonnage <- etude_reechantillonnage(pokemon_data, "Type.1",
c("Total", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed"),
ks, N)
# Analyser les résultats
taux_erreurs_moyens <- sapply(resultats_reechantillonnage, mean)
# Afficher les résultats
print(taux_erreurs_moyens)
