data_virginica<-subset(data, Species == "virginica")[1:y, ]
data_setosa<-subset(data, Species == "setosa")[1:z, ]
data_ech<-rbind(data_train_setosa,data_train_versicolor,data_train_virginica)[,1:5]
return(data_ech)
}
test_10_k<-function(donner,k){
#fonction qui fait le test des knn 10 foix
#entree: donner   dataframe   donnerbrut
#        k        integer     kvoisin
#sortie: la precision trouver
donner_ech<-creer_les_donner(donner)
donner_ech<-donner_ech[sample(nrow(donner_ech)), ]
donnertrain<-donner_ech[1:nrow(donner_ech)/2,1:4]
classtrain<-donner_ech[1:nrow(donner_ech)/2,5]
donnertest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),1:4]
classtest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),5]
prec<-fait_un_test(donnertrain,donnertest,classtrain,classtest,k)
for (i in 2:10){
donner_ech<-creer_les_donner(donner)
donner_ech<-donner_ech[sample(nrow(donner_ech)), ]
donnertrain<-donner_ech[1:nrow(donner_ech)/2,1:4]
classtrain<-donner_ech[1:nrow(donner_ech)/2,5]
donnertest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),1:4]
classtest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),5]
newprec<-fait_un_test(donnertrain,donnertest,classtrain,classtest,k)
if(newprec>=prec){prec<-newprec}
}
return(prec)
}
trouve_k_opt<-function(data,listek){
#trouve le k optimal par des test de knn
#entrer: data   dataframe donner
#        listek liste     liste des k a tester
k_opt<-listek[1]
precision<-test_10_k(data,k_opt)
for (i in 2:length(listek)){
new_precision<-test_10_k(data,listek[i])
if (new_precision>=precision){
k_opt<-listek[i]
precision<-new_precision
}
}
return(k_opt)
}
#QUESTION 4  Tester votre fonction sur le jeu entier
liste_k_voisin<-c(3,5,7)
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
#QUESTION 5  Programmer l’etude de reechantillonnage
#QUESTION 6  Tester votre programme sur le jeu entier
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
##################################
#TP Data Mining - Pratique sous R#
##################################
# INITIALISATION
library(class)
data_iris<-iris
#QUESTION 1  Decrire comment fonctionne cette procedure
#fonction qui vas chercher par la methode des knn les objet
#en fonction d'un echantillions d'entrainement
# en entrée
#     train : dataframe
#     le dataset des echantillions prit en donnée pour entrainer le modele
#     test : dataframe
#     le dataset des objet dont on cherche la classe
#     cl :  liste
#     la liste des classes
#     k :  integer
#     le chois du nombre de k voisin
# en sortie
#     liste
#     une liste des valeurs de classe trouver de chaque objet
#
#QUESTION 2  Tester cette procedure avec echantillon
#train
data_train_versicolor <- subset(data_iris, Species == "versicolor")[1:25, ]
data_train_virginica<-subset(data_iris, Species == "virginica")[1:25, ]
data_train_setosa<-subset(data_iris, Species == "setosa")[1:25, ]
data_train<-rbind(data_train_setosa,data_train_versicolor,data_train_virginica)[,1:4]
label_train<-c(rep("setosa",25),rep("versicolor",25),rep("virginica",25))
#test
data_test_versicolor <- subset(data_iris, Species == "versicolor")[26:50, ]
data_test_virginica<-subset(data_iris, Species == "virginica")[26:50, ]
data_test_setosa<-subset(data_iris, Species == "setosa")[26:50, ]
data_test<-rbind(data_test_setosa,data_test_versicolor,data_test_virginica)[,1:4]
label_test<-c(rep("setosa",25),rep("versicolor",25),rep("virginica",25))
#test des knn
test_resultat<-knn(train = data_train, test = data_test,cl = label_train,k = 3,use.all = FALSE,set.seed(4))
test_resultat
#calcule du tableau de confusion
tableau_confusion<-table(label_test,test_resultat)
#calcule du taux d'erreur
tauxerreur<-(tableau_confusion[1,2]+tableau_confusion[1,3]+tableau_confusion[2,3]+
tableau_confusion[2,1]+tableau_confusion[3,1]+tableau_confusion[3,2])/75
#calcule de la precision
precision<-(tableau_confusion[1,1]+tableau_confusion[2,2]+tableau_confusion[3,3])/
(tableau_confusion[1,2]+tableau_confusion[1,3]+tableau_confusion[2,3]+
tableau_confusion[2,1]+tableau_confusion[3,1]+tableau_confusion[3,2]+
tableau_confusion[1,1]+tableau_confusion[2,2]+tableau_confusion[3,3])
#resultat
tauxerreur
precision
#QUESTION 3  Programmer une fonction
fait_un_test <- function(donnertrain, donnertest, classetrain, classetest, k) {
# Crée un test de knn et teste avec une matrice de confusion la précision
test_resultat <- knn(train = donnertrain, test = donnertest, cl = classetrain, k = k, use.all = FALSE)
tableau_confusion <- table(classetest, test_resultat)
# Calcul de la précision
precision <- sum(diag(tableau_confusion)) / sum(tableau_confusion)
return(precision)
}
creer_les_donner<-function(data){
#a partir d'un tableau de donner creer un echantillions aleatoire
#entree: data   dataframe   donner a echantillionner
#sortie: data_ech dataframe donner echantillionner (data)
#creer les valeur aleatoire
x<-sample(15:25, 1)
y<-sample(15:25, 1)
z<-sample(15:25, 1)
x<-2*x
y<-2*y
z<-2*z
data_versicolor <- subset(data, Species == "versicolor")[1:x, ]
data_virginica<-subset(data, Species == "virginica")[1:y, ]
data_setosa<-subset(data, Species == "setosa")[1:z, ]
data_ech<-rbind(data_train_setosa,data_train_versicolor,data_train_virginica)[,1:5]
return(data_ech)
}
test_10_k<-function(donner,k){
#fonction qui fait le test des knn 10 foix
#entree: donner   dataframe   donnerbrut
#        k        integer     kvoisin
#sortie: la precision trouver
donner_ech<-creer_les_donner(donner)
donner_ech<-donner_ech[sample(nrow(donner_ech)), ]
donnertrain<-donner_ech[1:nrow(donner_ech)/2,1:4]
classtrain<-donner_ech[1:nrow(donner_ech)/2,5]
donnertest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),1:4]
classtest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),5]
prec<-fait_un_test(donnertrain,donnertest,classtrain,classtest,k)
for (i in 2:10){
donner_ech<-creer_les_donner(donner)
donner_ech<-donner_ech[sample(nrow(donner_ech)), ]
donnertrain<-donner_ech[1:nrow(donner_ech)/2,1:4]
classtrain<-donner_ech[1:nrow(donner_ech)/2,5]
donnertest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),1:4]
classtest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),5]
newprec<-fait_un_test(donnertrain,donnertest,classtrain,classtest,k)
if(newprec>=prec){prec<-newprec}
}
return(prec)
}
trouve_k_opt<-function(data,listek){
#trouve le k optimal par des test de knn
#entrer: data   dataframe donner
#        listek liste     liste des k a tester
k_opt<-listek[1]
precision<-test_10_k(data,k_opt)
for (i in 2:length(listek)){
new_precision<-test_10_k(data,listek[i])
if (new_precision>=precision){
k_opt<-listek[i]
precision<-new_precision
}
}
return(k_opt)
}
#QUESTION 4  Tester votre fonction sur le jeu entier
liste_k_voisin<-c(3,5,7)
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
library(class)
etude_reechantillonnage <- function(y, X, ks, N) {
n <- length(y)
taille_apprentissage <- floor(0.7 * n)
set.seed(123) # Pour rendre les résultats reproductibles
indices_apprentissage <- matrix(nrow = N, ncol = taille_apprentissage)
# Stocker les indices des échantillons d'apprentissage
for (i in 1:N) {
indices_apprentissage[i,] <- sample(1:n, taille_apprentissage)
}
resultats <- list()
# Boucle sur les N répétitions
for (i in 1:N) {
indices_test <- setdiff(1:n, indices_apprentissage[i,])
X_apprentissage <- X[indices_apprentissage[i,],]
y_apprentissage <- y[indices_apprentissage[i,]]
X_test <- X[indices_test,]
y_test <- y[indices_test]
erreurs <- numeric(length(ks))
precisions <- numeric(length(ks))
for (j in 1:length(ks)) {
k <- ks[j]
predictions <- knn(X_apprentissage, X_test, y_apprentissage, k = k)
mat_confusion <- table(y_test, predictions)
erreurs[j] <- 1 - sum(diag(mat_confusion)) / sum(mat_confusion)
precisions[j] <- sum(diag(mat_confusion)) / sum(mat_confusion)
}
k_opt <- ks[which.min(erreurs)]
erreur_opt <- min(erreurs)
precision_opt <- max(precisions)
resultats[[i]] <- list(k_optimal = k_opt, erreur = erreur_opt, precision = precision_opt)
}
return(resultats)
}
#QUESTION 6  Tester votre programme sur le jeu entier
X <- as.matrix(data_iris[, 1:4])  # Convertir les prédicteurs en matrice
y <- iris[, 5]              # La réponse est la colonne des espèces
# Définir les valeurs de k et le nombre de répétitions
ks <- c(1, 3, 5, 7, 9, 11)  # Exemple de valeurs de k
N <- 10                     # Nombre de répétitions
# Appeler la fonction etude_reechantillonnage
resultats <- etude_reechantillonnage(y, X, ks, N)
# Afficher les résultats
print(resultats)
ind.train <- c(1:25,51:75,101:125)
attach(iris)
res <- lda(formula=Species ~ ., data = iris, prior = c(1,1,1)/3,
subset = ind.train)
library(MASS)
library(class)
library(MASS)
data_iris<-iris
#QUESTION 1  Decrire comment fonctionne cette procedure
#fonction qui vas chercher par la methode des knn les objet
#en fonction d'un echantillions d'entrainement
# en entrée
#     train : dataframe
#     le dataset des echantillions prit en donnée pour entrainer le modele
#     test : dataframe
#     le dataset des objet dont on cherche la classe
#     cl :  liste
#     la liste des classes
#     k :  integer
#     le chois du nombre de k voisin
# en sortie
#     liste
#     une liste des valeurs de classe trouver de chaque objet
#
#QUESTION 2  Tester cette procedure avec echantillon
#train
data_train_versicolor <- subset(data_iris, Species == "versicolor")[1:25, ]
data_train_virginica<-subset(data_iris, Species == "virginica")[1:25, ]
data_train_setosa<-subset(data_iris, Species == "setosa")[1:25, ]
data_train<-rbind(data_train_setosa,data_train_versicolor,data_train_virginica)[,1:4]
label_train<-c(rep("setosa",25),rep("versicolor",25),rep("virginica",25))
#test
data_test_versicolor <- subset(data_iris, Species == "versicolor")[26:50, ]
data_test_virginica<-subset(data_iris, Species == "virginica")[26:50, ]
data_test_setosa<-subset(data_iris, Species == "setosa")[26:50, ]
data_test<-rbind(data_test_setosa,data_test_versicolor,data_test_virginica)[,1:4]
label_test<-c(rep("setosa",25),rep("versicolor",25),rep("virginica",25))
#test des knn
test_resultat<-knn(train = data_train, test = data_test,cl = label_train,k = 3,use.all = FALSE,set.seed(4))
test_resultat
#calcule du tableau de confusion
tableau_confusion<-table(label_test,test_resultat)
#calcule du taux d'erreur
tauxerreur<-(tableau_confusion[1,2]+tableau_confusion[1,3]+tableau_confusion[2,3]+
tableau_confusion[2,1]+tableau_confusion[3,1]+tableau_confusion[3,2])/75
#calcule de la precision
precision<-(tableau_confusion[1,1]+tableau_confusion[2,2]+tableau_confusion[3,3])/
(tableau_confusion[1,2]+tableau_confusion[1,3]+tableau_confusion[2,3]+
tableau_confusion[2,1]+tableau_confusion[3,1]+tableau_confusion[3,2]+
tableau_confusion[1,1]+tableau_confusion[2,2]+tableau_confusion[3,3])
#resultat
tauxerreur
precision
#QUESTION 3  Programmer une fonction
fait_un_test <- function(donnertrain, donnertest, classetrain, classetest, k) {
# Crée un test de knn et teste avec une matrice de confusion la précision
test_resultat <- knn(train = donnertrain, test = donnertest, cl = classetrain, k = k, use.all = FALSE)
tableau_confusion <- table(classetest, test_resultat)
# Calcul de la précision
precision <- sum(diag(tableau_confusion)) / sum(tableau_confusion)
return(precision)
}
creer_les_donner<-function(data){
#a partir d'un tableau de donner creer un echantillions aleatoire
#entree: data   dataframe   donner a echantillionner
#sortie: data_ech dataframe donner echantillionner (data)
#creer les valeur aleatoire
x<-sample(15:25, 1)
y<-sample(15:25, 1)
z<-sample(15:25, 1)
x<-2*x
y<-2*y
z<-2*z
data_versicolor <- subset(data, Species == "versicolor")[1:x, ]
data_virginica<-subset(data, Species == "virginica")[1:y, ]
data_setosa<-subset(data, Species == "setosa")[1:z, ]
data_ech<-rbind(data_train_setosa,data_train_versicolor,data_train_virginica)[,1:5]
return(data_ech)
}
test_10_k<-function(donner,k){
#fonction qui fait le test des knn 10 foix
#entree: donner   dataframe   donnerbrut
#        k        integer     kvoisin
#sortie: la precision trouver
donner_ech<-creer_les_donner(donner)
donner_ech<-donner_ech[sample(nrow(donner_ech)), ]
donnertrain<-donner_ech[1:nrow(donner_ech)/2,1:4]
classtrain<-donner_ech[1:nrow(donner_ech)/2,5]
donnertest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),1:4]
classtest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),5]
prec<-fait_un_test(donnertrain,donnertest,classtrain,classtest,k)
for (i in 2:10){
donner_ech<-creer_les_donner(donner)
donner_ech<-donner_ech[sample(nrow(donner_ech)), ]
donnertrain<-donner_ech[1:nrow(donner_ech)/2,1:4]
classtrain<-donner_ech[1:nrow(donner_ech)/2,5]
donnertest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),1:4]
classtest<-donner_ech[(nrow(donner_ech)/2):nrow(donner_ech),5]
newprec<-fait_un_test(donnertrain,donnertest,classtrain,classtest,k)
if(newprec>=prec){prec<-newprec}
}
return(prec)
}
trouve_k_opt<-function(data,listek){
#trouve le k optimal par des test de knn
#entrer: data   dataframe donner
#        listek liste     liste des k a tester
k_opt<-listek[1]
precision<-test_10_k(data,k_opt)
for (i in 2:length(listek)){
new_precision<-test_10_k(data,listek[i])
if (new_precision>=precision){
k_opt<-listek[i]
precision<-new_precision
}
}
return(k_opt)
}
#QUESTION 4  Tester votre fonction sur le jeu entier
liste_k_voisin<-c(3,5,7)
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
#QUESTION 5  Programmer l’etude de reechantillonnage
etude_reechantillonnage <- function(y, X, ks, N) {
n <- length(y)
taille_apprentissage <- floor(0.7 * n)
set.seed(123) # Pour rendre les résultats reproductibles
indices_apprentissage <- matrix(nrow = N, ncol = taille_apprentissage)
# Stocker les indices des échantillons d'apprentissage
for (i in 1:N) {
indices_apprentissage[i,] <- sample(1:n, taille_apprentissage)
}
resultats <- list()
# Boucle sur les N répétitions
for (i in 1:N) {
indices_test <- setdiff(1:n, indices_apprentissage[i,])
X_apprentissage <- X[indices_apprentissage[i,],]
y_apprentissage <- y[indices_apprentissage[i,]]
X_test <- X[indices_test,]
y_test <- y[indices_test]
erreurs <- numeric(length(ks))
precisions <- numeric(length(ks))
for (j in 1:length(ks)) {
k <- ks[j]
predictions <- knn(X_apprentissage, X_test, y_apprentissage, k = k)
mat_confusion <- table(y_test, predictions)
erreurs[j] <- 1 - sum(diag(mat_confusion)) / sum(mat_confusion)
precisions[j] <- sum(diag(mat_confusion)) / sum(mat_confusion)
}
k_opt <- ks[which.min(erreurs)]
erreur_opt <- min(erreurs)
precision_opt <- max(precisions)
resultats[[i]] <- list(k_optimal = k_opt, erreur = erreur_opt, precision = precision_opt)
}
return(resultats)
}
#QUESTION 6  Tester votre programme sur le jeu entier
X <- as.matrix(data_iris[, 1:4])  # Convertir les prédicteurs en matrice
y <- iris[, 5]              # La réponse est la colonne des espèces
# Définir les valeurs de k et le nombre de répétitions
ks <- c(1, 3, 5, 7, 9, 11)  # Exemple de valeurs de k
N <- 10                     # Nombre de répétitions
# Appeler la fonction etude_reechantillonnage
resultats <- etude_reechantillonnage(y, X, ks, N)
# Afficher les résultats
print(resultats)
#QUESTION 1
ind.train <- c(1:25,51:75,101:125)
attach(iris)
res <- lda(formula=Species ~ ., data = iris, prior = c(1,1,1)/3,
subset = ind.train)
respredict <- predict(res, iris[-ind.train, ])
res
respredict
ind.train <- c(1:25,51:75,101:125)
attach(iris)
res <- lda(formula=Species ~ ., data = iris, prior = c(1,1,1)/3,
subset = ind.train)
respredict <- predict(res, iris[-ind.train, ])
respredict$class
respredict$posterior
etude_reechantillonnage <- function(y, X, ks, N) {
n <- length(y)
taille_apprentissage <- floor(0.7 * n)
set.seed(123) # Pour rendre les résultats reproductibles
indices_apprentissage <- matrix(nrow = N, ncol = taille_apprentissage)
# Stocker les indices des échantillons d'apprentissage
for (i in 1:N) {
indices_apprentissage[i,] <- sample(1:n, taille_apprentissage)
}
resultats <- list()
# Boucle sur les N répétitions
for (i in 1:N) {
indices_test <- setdiff(1:n, indices_apprentissage[i,])
X_apprentissage <- X[indices_apprentissage[i,],]
y_apprentissage <- y[indices_apprentissage[i,]]
X_test <- X[indices_test,]
y_test <- y[indices_test]
erreurs <- numeric(length(ks))
precisions <- numeric(length(ks))
for (j in 1:length(ks)) {
k <- ks[j]
predictions <- knn(X_apprentissage, X_test, y_apprentissage, k = k)
mat_confusion <- table(y_test, predictions)
erreurs[j] <- 1 - sum(diag(mat_confusion)) / sum(mat_confusion)
precisions[j] <- sum(diag(mat_confusion)) / sum(mat_confusion)
}
k_opt <- ks[which.min(erreurs)]
erreur_opt <- min(erreurs)
precision_opt <- max(precisions)
resultats[[i]] <- list(k_optimal = k_opt, erreur = erreur_opt, precision = precision_opt)
}
return(resultats)
}
#QUESTION 6  Tester votre programme sur le jeu entier
X <- as.matrix(data_iris[, 1:4])  # Convertir les prédicteurs en matrice
y <- iris[, 5]              # La réponse est la colonne des espèces
# Définir les valeurs de k et le nombre de répétitions
ks <- c(1, 3, 5, 7, 9, 11)  # Exemple de valeurs de k
N <- 10                     # Nombre de répétitions
# Appeler la fonction etude_reechantillonnage
resultats <- etude_reechantillonnage(y, X, ks, N)
# Afficher les résultats
print(resultats)
#QUESTION 4  Tester votre fonction sur le jeu entier
liste_k_voisin<-c(3,5,7)
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
#QUESTION 4  Tester votre fonction sur le jeu entier
liste_k_voisin<-c(3,5,7)
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
#QUESTION 4  Tester votre fonction sur le jeu entier
liste_k_voisin<-c(3,5,7)
k_optimale<-trouve_k_opt(data_iris,liste_k_voisin)
k_optimale
